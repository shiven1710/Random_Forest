{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "Python 3.7.9 64-bit ('base': conda)",
      "display_name": "Python 3.7.9 64-bit ('base': conda)",
      "metadata": {
        "interpreter": {
          "hash": "a8f61be024eba58adef938c9aa1e29e02cb3dece83a5348b1a2dafd16a070453"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.7.9-final"
    },
    "colab": {
      "name": "Task 1 - RandomForest_from_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5A6n7jvYxPC"
      },
      "source": [
        "#Vehicle silhouettes\n",
        "\n",
        "##Objective\n",
        "To classify a given silhouette as one of four types of vehicle, \tusing a set of features extracted from the silhouette. The \tvehicle may be viewed from one of many different angles.   \n",
        "\n",
        "##Description\n",
        "\n",
        "###The features were extracted from the silhouettes by the HIPS\n",
        "(Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale independent features utilising\tboth classical moments based measures such as scaled variance,\tskewness and kurtosis about the major/minor axes and heuristic\tmeasures such as hollows, circularity, rectangularity and\tcompactness. Four \"Corgie\" model vehicles were used for the experiment: a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.\tThis particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.\n",
        "\t\n",
        "##Source: https://www.kaggle.com/rajansharma780/vehicle\n",
        "\n",
        "## ATTRIBUTES\n",
        "1.\tcompactness\tfloat\taverage perimeter**2/area\n",
        "2.\tcircularity\tfloat\taverage radius**2/area\n",
        "3.\tdistance_circularity\tfloat\tarea/(av.distance from border)**2\n",
        "4.\tradius_ratio\tfloat\t(max.rad-min.rad)/av.radius\n",
        "5.\tpr_axis_aspect_ratio\tfloat\t(minor axis)/(major axis)\n",
        "6.\tmax_length_aspect_ratio\tfloat\t(length perp. max length)/(max length)\n",
        "7.\tscatter_ratio\tfloat\t(inertia about minor axis)/(inertia about major axis)\n",
        "8.\telongatedness\tfloat\tarea/(shrink width)**2\n",
        "9.\tpr_axis_rectangularity\tfloat\tarea/(pr.axis length*pr.axis width)\n",
        "10.\tmax_length_rectangularity\tfloat\tarea/(max.length*length perp. to this)\n",
        "11.\tscaled_variance_major_axis\tfloat\t(2nd order moment about minor axis)/area\n",
        "12.\tscaled_variance_minor_axis\tfloat\t(2nd order moment about major axis)/area\n",
        "13.\tscaled_radius_gyration\tfloat\t(mavar+mivar)/area\n",
        "14.\tskewness_major_axis\tfloat\t(3rd order moment about major axis)/sigma_min**3\n",
        "15.\tskewness_minor_axis\tfloat\t(3rd order moment about minor axis)/sigma_maj**3\n",
        "16.\tkurtosis_minor_axis\tfloat\t(4th order moment about major axis)/sigma_min**4\n",
        "17.\tkurtosis_major_axis\tfloat\t(4th order moment about minor axis)/sigma_maj**4\n",
        "18.\thollows_ratio\tfloat\t(area of hollows)/(area of bounding polygon)\n",
        "\n",
        "##Target variable\n",
        "19.\tvehicle_class\tstring\tPredictor Class. Values: Opel, Saab, Bus, Van\t\n",
        "\n",
        "#Tasks:\n",
        "1.\tObtain the multi-class dataset from the given link\n",
        "2.\tLoad the dataset\n",
        "3.\tApply pre-processing techniques: Encoding, Scaling\n",
        "4.\tDivide the dataset into training (70%) and testing (30%)\n",
        "5.\tBuild your own random forest model from scratch (using invidual decision tree model from sklearn)\n",
        "6.\tTrain the random forest model\n",
        "7.\tTest the random forest model\n",
        "8.\tTrain and test the random forest model using sklearn.\n",
        "9.\tCompare the performance of both the models\n",
        "\n",
        "##Useful links:\n",
        "https://machinelearningmastery.com/implement-random-forest-scratch-python/\n",
        "\n",
        "https://towardsdatascience.com/random-forests-and-decision-trees-from-scratch-in-python-3e4fa5ae4249\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2018/12/building-a-random-forest-from-scratch-understanding-real-world-data-products-ml-for-programmers-part-3/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FoSpD3QDP4"
      },
      "source": [
        "# Part 1: Random Forest from scratch\n",
        "\n",
        "Random forests are an ensemble learning method for classification and regression that operate by constructing multiple decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q0F2HVFPl0R",
        "tags": []
      },
      "source": [
        "# Load the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier,VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn import tree\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VACehGfwPoAg"
      },
      "source": [
        "# Load the dataset \n",
        "data=pd.read_csv(\"vehicle.csv\")\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     compactness  circularity  distance_circularity  radius_ratio  \\\n0             95         48.0                  83.0         178.0   \n1             91         41.0                  84.0         141.0   \n2            104         50.0                 106.0         209.0   \n3             93         41.0                  82.0         159.0   \n4             85         44.0                  70.0         205.0   \n..           ...          ...                   ...           ...   \n841           93         39.0                  87.0         183.0   \n842           89         46.0                  84.0         163.0   \n843          106         54.0                 101.0         222.0   \n844           86         36.0                  78.0         146.0   \n845           85         36.0                  66.0         123.0   \n\n     pr.axis_aspect_ratio  max.length_aspect_ratio  scatter_ratio  \\\n0                    72.0                       10          162.0   \n1                    57.0                        9          149.0   \n2                    66.0                       10          207.0   \n3                    63.0                        9          144.0   \n4                   103.0                       52          149.0   \n..                    ...                      ...            ...   \n841                  64.0                        8          169.0   \n842                  66.0                       11          159.0   \n843                  67.0                       12          222.0   \n844                  58.0                        7          135.0   \n845                  55.0                        5          120.0   \n\n     elongatedness  pr.axis_rectangularity  max.length_rectangularity  \\\n0             42.0                    20.0                        159   \n1             45.0                    19.0                        143   \n2             32.0                    23.0                        158   \n3             46.0                    19.0                        143   \n4             45.0                    19.0                        144   \n..             ...                     ...                        ...   \n841           40.0                    20.0                        134   \n842           43.0                    20.0                        159   \n843           30.0                    25.0                        173   \n844           50.0                    18.0                        124   \n845           56.0                    17.0                        128   \n\n     scaled_variance  scaled_variance.1  scaled_radius_of_gyration  \\\n0              176.0              379.0                      184.0   \n1              170.0              330.0                      158.0   \n2              223.0              635.0                      220.0   \n3              160.0              309.0                      127.0   \n4              241.0              325.0                      188.0   \n..               ...                ...                        ...   \n841            200.0              422.0                      149.0   \n842            173.0              368.0                      176.0   \n843            228.0              721.0                      200.0   \n844            155.0              270.0                      148.0   \n845            140.0              212.0                      131.0   \n\n     scaled_radius_of_gyration.1  skewness_about  skewness_about.1  \\\n0                           70.0             6.0              16.0   \n1                           72.0             9.0              14.0   \n2                           73.0            14.0               9.0   \n3                           63.0             6.0              10.0   \n4                          127.0             9.0              11.0   \n..                           ...             ...               ...   \n841                         72.0             7.0              25.0   \n842                         72.0             1.0              20.0   \n843                         70.0             3.0               4.0   \n844                         66.0             0.0              25.0   \n845                         73.0             1.0              18.0   \n\n     skewness_about.2  hollows_ratio class  \n0               187.0            197   van  \n1               189.0            199   van  \n2               188.0            196   car  \n3               199.0            207   van  \n4               180.0            183   bus  \n..                ...            ...   ...  \n841             188.0            195   car  \n842             186.0            197   van  \n843             187.0            201   car  \n844             190.0            195   car  \n845             186.0            190   van  \n\n[846 rows x 19 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>compactness</th>\n      <th>circularity</th>\n      <th>distance_circularity</th>\n      <th>radius_ratio</th>\n      <th>pr.axis_aspect_ratio</th>\n      <th>max.length_aspect_ratio</th>\n      <th>scatter_ratio</th>\n      <th>elongatedness</th>\n      <th>pr.axis_rectangularity</th>\n      <th>max.length_rectangularity</th>\n      <th>scaled_variance</th>\n      <th>scaled_variance.1</th>\n      <th>scaled_radius_of_gyration</th>\n      <th>scaled_radius_of_gyration.1</th>\n      <th>skewness_about</th>\n      <th>skewness_about.1</th>\n      <th>skewness_about.2</th>\n      <th>hollows_ratio</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>95</td>\n      <td>48.0</td>\n      <td>83.0</td>\n      <td>178.0</td>\n      <td>72.0</td>\n      <td>10</td>\n      <td>162.0</td>\n      <td>42.0</td>\n      <td>20.0</td>\n      <td>159</td>\n      <td>176.0</td>\n      <td>379.0</td>\n      <td>184.0</td>\n      <td>70.0</td>\n      <td>6.0</td>\n      <td>16.0</td>\n      <td>187.0</td>\n      <td>197</td>\n      <td>van</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>91</td>\n      <td>41.0</td>\n      <td>84.0</td>\n      <td>141.0</td>\n      <td>57.0</td>\n      <td>9</td>\n      <td>149.0</td>\n      <td>45.0</td>\n      <td>19.0</td>\n      <td>143</td>\n      <td>170.0</td>\n      <td>330.0</td>\n      <td>158.0</td>\n      <td>72.0</td>\n      <td>9.0</td>\n      <td>14.0</td>\n      <td>189.0</td>\n      <td>199</td>\n      <td>van</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>104</td>\n      <td>50.0</td>\n      <td>106.0</td>\n      <td>209.0</td>\n      <td>66.0</td>\n      <td>10</td>\n      <td>207.0</td>\n      <td>32.0</td>\n      <td>23.0</td>\n      <td>158</td>\n      <td>223.0</td>\n      <td>635.0</td>\n      <td>220.0</td>\n      <td>73.0</td>\n      <td>14.0</td>\n      <td>9.0</td>\n      <td>188.0</td>\n      <td>196</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>93</td>\n      <td>41.0</td>\n      <td>82.0</td>\n      <td>159.0</td>\n      <td>63.0</td>\n      <td>9</td>\n      <td>144.0</td>\n      <td>46.0</td>\n      <td>19.0</td>\n      <td>143</td>\n      <td>160.0</td>\n      <td>309.0</td>\n      <td>127.0</td>\n      <td>63.0</td>\n      <td>6.0</td>\n      <td>10.0</td>\n      <td>199.0</td>\n      <td>207</td>\n      <td>van</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>85</td>\n      <td>44.0</td>\n      <td>70.0</td>\n      <td>205.0</td>\n      <td>103.0</td>\n      <td>52</td>\n      <td>149.0</td>\n      <td>45.0</td>\n      <td>19.0</td>\n      <td>144</td>\n      <td>241.0</td>\n      <td>325.0</td>\n      <td>188.0</td>\n      <td>127.0</td>\n      <td>9.0</td>\n      <td>11.0</td>\n      <td>180.0</td>\n      <td>183</td>\n      <td>bus</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>93</td>\n      <td>39.0</td>\n      <td>87.0</td>\n      <td>183.0</td>\n      <td>64.0</td>\n      <td>8</td>\n      <td>169.0</td>\n      <td>40.0</td>\n      <td>20.0</td>\n      <td>134</td>\n      <td>200.0</td>\n      <td>422.0</td>\n      <td>149.0</td>\n      <td>72.0</td>\n      <td>7.0</td>\n      <td>25.0</td>\n      <td>188.0</td>\n      <td>195</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>89</td>\n      <td>46.0</td>\n      <td>84.0</td>\n      <td>163.0</td>\n      <td>66.0</td>\n      <td>11</td>\n      <td>159.0</td>\n      <td>43.0</td>\n      <td>20.0</td>\n      <td>159</td>\n      <td>173.0</td>\n      <td>368.0</td>\n      <td>176.0</td>\n      <td>72.0</td>\n      <td>1.0</td>\n      <td>20.0</td>\n      <td>186.0</td>\n      <td>197</td>\n      <td>van</td>\n    </tr>\n    <tr>\n      <th>843</th>\n      <td>106</td>\n      <td>54.0</td>\n      <td>101.0</td>\n      <td>222.0</td>\n      <td>67.0</td>\n      <td>12</td>\n      <td>222.0</td>\n      <td>30.0</td>\n      <td>25.0</td>\n      <td>173</td>\n      <td>228.0</td>\n      <td>721.0</td>\n      <td>200.0</td>\n      <td>70.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>187.0</td>\n      <td>201</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>86</td>\n      <td>36.0</td>\n      <td>78.0</td>\n      <td>146.0</td>\n      <td>58.0</td>\n      <td>7</td>\n      <td>135.0</td>\n      <td>50.0</td>\n      <td>18.0</td>\n      <td>124</td>\n      <td>155.0</td>\n      <td>270.0</td>\n      <td>148.0</td>\n      <td>66.0</td>\n      <td>0.0</td>\n      <td>25.0</td>\n      <td>190.0</td>\n      <td>195</td>\n      <td>car</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>85</td>\n      <td>36.0</td>\n      <td>66.0</td>\n      <td>123.0</td>\n      <td>55.0</td>\n      <td>5</td>\n      <td>120.0</td>\n      <td>56.0</td>\n      <td>17.0</td>\n      <td>128</td>\n      <td>140.0</td>\n      <td>212.0</td>\n      <td>131.0</td>\n      <td>73.0</td>\n      <td>1.0</td>\n      <td>18.0</td>\n      <td>186.0</td>\n      <td>190</td>\n      <td>van</td>\n    </tr>\n  </tbody>\n</table>\n<p>846 rows × 19 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S47gOYRhPqKF"
      },
      "source": [
        "# Preprocessing\n",
        "# Encoding categorical variables (if any)\n",
        "# Feature Scaling\n",
        "# Filling missing values (if any)\n",
        "le=LabelEncoder()\n",
        "temp=le.fit_transform(data[\"class\"])\n",
        "minmax=MinMaxScaler()\n",
        "data=pd.DataFrame(minmax.fit_transform(data.iloc[:,:-1]),columns=data.iloc[:,:-1].columns)\n",
        "data[\"class\"]=temp\n",
        "data=data.fillna(0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "     compactness  circularity  distance_circularity  radius_ratio  \\\n0       0.478261     0.576923              0.597222      0.323144   \n1       0.391304     0.307692              0.611111      0.161572   \n2       0.673913     0.653846              0.916667      0.458515   \n3       0.434783     0.307692              0.583333      0.240175   \n4       0.260870     0.423077              0.416667      0.441048   \n..           ...          ...                   ...           ...   \n841     0.434783     0.230769              0.652778      0.344978   \n842     0.347826     0.500000              0.611111      0.257642   \n843     0.717391     0.807692              0.847222      0.515284   \n844     0.282609     0.115385              0.527778      0.183406   \n845     0.260870     0.115385              0.361111      0.082969   \n\n     pr.axis_aspect_ratio  max.length_aspect_ratio  scatter_ratio  \\\n0                0.274725                 0.150943       0.326797   \n1                0.109890                 0.132075       0.241830   \n2                0.208791                 0.150943       0.620915   \n3                0.175824                 0.132075       0.209150   \n4                0.615385                 0.943396       0.241830   \n..                    ...                      ...            ...   \n841              0.186813                 0.113208       0.372549   \n842              0.208791                 0.169811       0.307190   \n843              0.219780                 0.188679       0.718954   \n844              0.120879                 0.094340       0.150327   \n845              0.087912                 0.056604       0.052288   \n\n     elongatedness  pr.axis_rectangularity  max.length_rectangularity  \\\n0         0.457143                0.250000                   0.585714   \n1         0.542857                0.166667                   0.357143   \n2         0.171429                0.500000                   0.571429   \n3         0.571429                0.166667                   0.357143   \n4         0.542857                0.166667                   0.371429   \n..             ...                     ...                        ...   \n841       0.400000                0.250000                   0.228571   \n842       0.485714                0.250000                   0.585714   \n843       0.114286                0.666667                   0.785714   \n844       0.685714                0.083333                   0.085714   \n845       0.857143                0.000000                   0.142857   \n\n     scaled_variance  scaled_variance.1  scaled_radius_of_gyration  \\\n0           0.242105           0.233813                   0.471698   \n1           0.210526           0.175060                   0.308176   \n2           0.489474           0.540767                   0.698113   \n3           0.157895           0.149880                   0.113208   \n4           0.584211           0.169065                   0.496855   \n..               ...                ...                        ...   \n841         0.368421           0.285372                   0.251572   \n842         0.226316           0.220624                   0.421384   \n843         0.515789           0.643885                   0.572327   \n844         0.131579           0.103118                   0.245283   \n845         0.052632           0.033573                   0.138365   \n\n     scaled_radius_of_gyration.1  skewness_about  skewness_about.1  \\\n0                       0.144737        0.272727          0.390244   \n1                       0.171053        0.409091          0.341463   \n2                       0.184211        0.636364          0.219512   \n3                       0.052632        0.272727          0.243902   \n4                       0.894737        0.409091          0.268293   \n..                           ...             ...               ...   \n841                     0.171053        0.318182          0.609756   \n842                     0.171053        0.045455          0.487805   \n843                     0.144737        0.136364          0.097561   \n844                     0.092105        0.000000          0.609756   \n845                     0.184211        0.045455          0.439024   \n\n     skewness_about.2  hollows_ratio  class  \n0            0.366667       0.533333      2  \n1            0.433333       0.600000      2  \n2            0.400000       0.500000      1  \n3            0.766667       0.866667      2  \n4            0.133333       0.066667      0  \n..                ...            ...    ...  \n841          0.400000       0.466667      1  \n842          0.333333       0.533333      2  \n843          0.366667       0.666667      1  \n844          0.466667       0.466667      1  \n845          0.333333       0.300000      2  \n\n[846 rows x 19 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>compactness</th>\n      <th>circularity</th>\n      <th>distance_circularity</th>\n      <th>radius_ratio</th>\n      <th>pr.axis_aspect_ratio</th>\n      <th>max.length_aspect_ratio</th>\n      <th>scatter_ratio</th>\n      <th>elongatedness</th>\n      <th>pr.axis_rectangularity</th>\n      <th>max.length_rectangularity</th>\n      <th>scaled_variance</th>\n      <th>scaled_variance.1</th>\n      <th>scaled_radius_of_gyration</th>\n      <th>scaled_radius_of_gyration.1</th>\n      <th>skewness_about</th>\n      <th>skewness_about.1</th>\n      <th>skewness_about.2</th>\n      <th>hollows_ratio</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.478261</td>\n      <td>0.576923</td>\n      <td>0.597222</td>\n      <td>0.323144</td>\n      <td>0.274725</td>\n      <td>0.150943</td>\n      <td>0.326797</td>\n      <td>0.457143</td>\n      <td>0.250000</td>\n      <td>0.585714</td>\n      <td>0.242105</td>\n      <td>0.233813</td>\n      <td>0.471698</td>\n      <td>0.144737</td>\n      <td>0.272727</td>\n      <td>0.390244</td>\n      <td>0.366667</td>\n      <td>0.533333</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.391304</td>\n      <td>0.307692</td>\n      <td>0.611111</td>\n      <td>0.161572</td>\n      <td>0.109890</td>\n      <td>0.132075</td>\n      <td>0.241830</td>\n      <td>0.542857</td>\n      <td>0.166667</td>\n      <td>0.357143</td>\n      <td>0.210526</td>\n      <td>0.175060</td>\n      <td>0.308176</td>\n      <td>0.171053</td>\n      <td>0.409091</td>\n      <td>0.341463</td>\n      <td>0.433333</td>\n      <td>0.600000</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.673913</td>\n      <td>0.653846</td>\n      <td>0.916667</td>\n      <td>0.458515</td>\n      <td>0.208791</td>\n      <td>0.150943</td>\n      <td>0.620915</td>\n      <td>0.171429</td>\n      <td>0.500000</td>\n      <td>0.571429</td>\n      <td>0.489474</td>\n      <td>0.540767</td>\n      <td>0.698113</td>\n      <td>0.184211</td>\n      <td>0.636364</td>\n      <td>0.219512</td>\n      <td>0.400000</td>\n      <td>0.500000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.434783</td>\n      <td>0.307692</td>\n      <td>0.583333</td>\n      <td>0.240175</td>\n      <td>0.175824</td>\n      <td>0.132075</td>\n      <td>0.209150</td>\n      <td>0.571429</td>\n      <td>0.166667</td>\n      <td>0.357143</td>\n      <td>0.157895</td>\n      <td>0.149880</td>\n      <td>0.113208</td>\n      <td>0.052632</td>\n      <td>0.272727</td>\n      <td>0.243902</td>\n      <td>0.766667</td>\n      <td>0.866667</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.260870</td>\n      <td>0.423077</td>\n      <td>0.416667</td>\n      <td>0.441048</td>\n      <td>0.615385</td>\n      <td>0.943396</td>\n      <td>0.241830</td>\n      <td>0.542857</td>\n      <td>0.166667</td>\n      <td>0.371429</td>\n      <td>0.584211</td>\n      <td>0.169065</td>\n      <td>0.496855</td>\n      <td>0.894737</td>\n      <td>0.409091</td>\n      <td>0.268293</td>\n      <td>0.133333</td>\n      <td>0.066667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>841</th>\n      <td>0.434783</td>\n      <td>0.230769</td>\n      <td>0.652778</td>\n      <td>0.344978</td>\n      <td>0.186813</td>\n      <td>0.113208</td>\n      <td>0.372549</td>\n      <td>0.400000</td>\n      <td>0.250000</td>\n      <td>0.228571</td>\n      <td>0.368421</td>\n      <td>0.285372</td>\n      <td>0.251572</td>\n      <td>0.171053</td>\n      <td>0.318182</td>\n      <td>0.609756</td>\n      <td>0.400000</td>\n      <td>0.466667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>842</th>\n      <td>0.347826</td>\n      <td>0.500000</td>\n      <td>0.611111</td>\n      <td>0.257642</td>\n      <td>0.208791</td>\n      <td>0.169811</td>\n      <td>0.307190</td>\n      <td>0.485714</td>\n      <td>0.250000</td>\n      <td>0.585714</td>\n      <td>0.226316</td>\n      <td>0.220624</td>\n      <td>0.421384</td>\n      <td>0.171053</td>\n      <td>0.045455</td>\n      <td>0.487805</td>\n      <td>0.333333</td>\n      <td>0.533333</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>843</th>\n      <td>0.717391</td>\n      <td>0.807692</td>\n      <td>0.847222</td>\n      <td>0.515284</td>\n      <td>0.219780</td>\n      <td>0.188679</td>\n      <td>0.718954</td>\n      <td>0.114286</td>\n      <td>0.666667</td>\n      <td>0.785714</td>\n      <td>0.515789</td>\n      <td>0.643885</td>\n      <td>0.572327</td>\n      <td>0.144737</td>\n      <td>0.136364</td>\n      <td>0.097561</td>\n      <td>0.366667</td>\n      <td>0.666667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>844</th>\n      <td>0.282609</td>\n      <td>0.115385</td>\n      <td>0.527778</td>\n      <td>0.183406</td>\n      <td>0.120879</td>\n      <td>0.094340</td>\n      <td>0.150327</td>\n      <td>0.685714</td>\n      <td>0.083333</td>\n      <td>0.085714</td>\n      <td>0.131579</td>\n      <td>0.103118</td>\n      <td>0.245283</td>\n      <td>0.092105</td>\n      <td>0.000000</td>\n      <td>0.609756</td>\n      <td>0.466667</td>\n      <td>0.466667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>845</th>\n      <td>0.260870</td>\n      <td>0.115385</td>\n      <td>0.361111</td>\n      <td>0.082969</td>\n      <td>0.087912</td>\n      <td>0.056604</td>\n      <td>0.052288</td>\n      <td>0.857143</td>\n      <td>0.000000</td>\n      <td>0.142857</td>\n      <td>0.052632</td>\n      <td>0.033573</td>\n      <td>0.138365</td>\n      <td>0.184211</td>\n      <td>0.045455</td>\n      <td>0.439024</td>\n      <td>0.333333</td>\n      <td>0.300000</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>846 rows × 19 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "x=data.iloc[:,:-1]\n",
        "y=data.iloc[:,-1:]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJGz-VZP2R9"
      },
      "source": [
        "# Divide the dataset to training and testing set\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hu9YAA53YxPG"
      },
      "source": [
        "# Randomly choose the features from training set and build decision tree\n",
        "# Randomness in the features will help us to achieve different DTrees every time\n",
        "# You can keep minimum number of random features every time so that trees will have sufficient features\n",
        "# Note: You can use builtin function for DT training using Sklearn\n",
        "def choose(x_train,x_test):\n",
        "    minrand=4\n",
        "    rand=random.randint(minrand,len(x_train.columns)-1)\n",
        "    if(rand>minrand):\n",
        "        minrand=rand\n",
        "    feat=[0,1,2,3]\n",
        "    temp_train=pd.DataFrame(x_train.iloc[:,:4],columns=x_train.iloc[:,:4].columns)\n",
        "    temp_test=pd.DataFrame(x_test.iloc[:,:4],columns=x_test.iloc[:,:4].columns)\n",
        "    columns=x.columns\n",
        "    while(len(feat)!=minrand):\n",
        "        ind=random.randint(0,len(x_train.columns)-1)\n",
        "        if(ind not in feat):\n",
        "            temp_train[columns[ind]]=x_train.iloc[:,ind]\n",
        "            temp_test[columns[ind]]=x_test.iloc[:,ind]\n",
        "            feat.append(ind)\n",
        "    return temp_train,temp_test"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22bKlgbZYxPQ",
        "tags": []
      },
      "source": [
        "# Train N number of decision trees using random feature selection strategy\n",
        "# Number of trees N can be user input\n",
        "n=int(input())\n",
        "trees=[]\n",
        "random_x_train=[None for i in range(n)]\n",
        "random_x_test=[None for i in range(n)]\n",
        "for i in range(n):\n",
        "    random_x_train[i],random_x_test[i]=choose(x_train,x_test)\n",
        "    dt=DecisionTreeClassifier()\n",
        "    dt.fit(random_x_train[i],y_train)\n",
        "    trees.append(dt)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mode(p):\n",
        "    fp=[]\n",
        "    for i in range(len(p[0])):\n",
        "        nz,no,nt=0,0,0\n",
        "        for j in range(len(p)):\n",
        "            if(p[j][i]==0):\n",
        "                nz+=1\n",
        "            elif(p[j][i]==1):\n",
        "                no+=1\n",
        "            else:\n",
        "                nt+=1\n",
        "        m=max(nz,no,nt)\n",
        "        if(m==nz):\n",
        "            fp.append(0)\n",
        "        elif(m==no):\n",
        "            fp.append(1)\n",
        "        else:\n",
        "            fp.append(2)\n",
        "    return fp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def average(p):\n",
        "    fp=[]\n",
        "    for i in range(len(p[0])):\n",
        "        avg=0\n",
        "        for j in range(len(p)):\n",
        "            avg+=p[j][i]\n",
        "        fp.append(avg/10)\n",
        "    return fp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXBsseNEYxPX",
        "tags": []
      },
      "source": [
        "# Apply different voting mechanisms such as \n",
        "# max voting/average voting/weighted average voting (using accuracy as weightage)\n",
        "# Perform the ensembling for the training set.\n",
        "print(\"Max Voting\")\n",
        "pred=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_train[j]))\n",
        "fp=mode(pred)\n",
        "print(\"Final Prediction\",fp)\n",
        "print(\"Average Voting\")\n",
        "pred=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_train[j]))\n",
        "fp=average(pred)\n",
        "print(\"Final Prediction\",fp)\n",
        "print(\"Weighted Average Voting\")\n",
        "pred=[]\n",
        "acc=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_train[j]))\n",
        "    acc.append(accuracy_score(y_train,pred[j]))\n",
        "acc=np.array(acc)\n",
        "for i in range(len(pred)):\n",
        "    pred[i]=(pred[i]*acc[i])\n",
        "fp=average(pred)\n",
        "print(\"Final Prediction\",fp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Max Voting\nFinal Prediction [1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 0, 2, 1, 0, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 0, 1, 1, 2, 2, 1, 0, 0, 0, 2, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 0, 1, 1, 1, 2, 1, 0, 2, 2, 2, 0, 1, 0, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 1, 1, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 0, 2, 0, 1, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 0, 2, 2, 1, 1, 2, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 2, 2, 0, 1, 2, 1, 0, 0, 1, 2, 2, 0, 2, 2, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 1, 0, 1, 1, 0, 0, 2, 1, 0, 0, 1, 1, 0, 2, 1, 1, 2, 0, 0, 0, 2, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 2, 0, 1, 0, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 0, 0, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 0, 2, 1, 2, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 0, 0, 1, 0, 0, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 2, 1, 1, 2, 0, 1, 0, 0, 1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 2, 1, 2, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 2, 1, 2, 2, 1, 2, 1, 1, 2, 0, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 0, 0, 2, 1, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 2, 1, 0, 1, 2, 1, 0, 0, 1, 1, 2, 0, 0, 1, 1, 1, 0, 1, 0, 2]\nAverage Voting\nFinal Prediction [1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0]\nWeighted Average Voting\nFinal Prediction [1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFEQjBB3RBpM",
        "tags": []
      },
      "source": [
        "# Apply invidual trees trained on the testingset\n",
        "# Note: You should've saved the feature sets used for training invidual trees,\n",
        "# so that same features can be chosen in testing set\n",
        "\n",
        "# Get predictions on testing set\n",
        "pred=[]\n",
        "for j in range(n):\n",
        "    print(\"Tree\",(j+1))\n",
        "    pred.append(trees[j].predict(random_x_test[j]))\n",
        "    print(pred[j])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tree 1\n[1 0 1 2 1 1 1 0 1 0 1 0 2 0 0 1 2 2 1 1 2 1 0 1 2 1 2 0 2 0 0 2 1 2 1 1 0\n 1 1 0 0 0 1 1 1 2 2 0 0 0 1 0 0 1 0 0 0 1 0 2 1 0 1 1 0 2 1 1 1 1 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 2 1 1 1 1 2 0 2 0 0 2 1 1 0 1 0 2 1 1 1 1 1\n 1 0 1 2 2 2 1 2 0 1 0 1 2 2 1 2 1 2 0 0 1 2 1 1 1 0 1 1 1 1 1 0 1 1 0 1 1\n 1 0 1 1 2 1 2 1 1 2 0 0 1 1 1 0 2 2 1 1 2 1 2 1 1 1 1 2 1 1 0 2 1 0 1 1 0\n 1 0 0 1 1 0 2 1 2 2 1 1 2 1 2 0 1 0 1 1 1 2 0 2 1 2 1 2 1 2 0 2 0 1 0 1 2\n 1 2 0 1 2 2 0 1 0 2 1 2 1 2 2 1 1 0 1 0 0 0 1 1 1 1 1 0 1 2 0 1]\nTree 2\n[0 0 1 2 1 2 0 0 1 0 1 1 0 1 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 1 2 1 2 1 1 1\n 1 1 0 0 0 1 1 1 2 2 0 0 0 1 0 1 1 0 0 1 2 1 2 1 0 1 1 0 1 2 1 1 0 2 1 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 0 0 1 1 1 1 1 2 1 2 1 0 2 1 1 0 1 0 2 1 1 0 1 2\n 1 0 1 2 2 2 2 2 1 1 1 1 2 2 1 2 1 2 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 2\n 1 0 1 2 2 1 2 1 1 0 0 0 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 2 1 1 0 0 1 0 1 1 1\n 1 0 0 1 1 2 2 1 2 2 1 1 2 1 2 0 1 0 1 1 1 2 0 2 1 2 1 2 1 2 0 1 0 0 0 1 2\n 0 2 0 1 2 2 0 1 0 2 1 2 1 2 1 1 1 1 1 0 1 2 1 1 1 1 1 0 1 1 0 1]\nTree 3\n[2 0 1 2 1 2 1 0 1 0 1 0 1 1 0 1 2 0 1 1 0 1 0 1 2 1 2 0 2 0 1 1 1 2 1 1 0\n 1 2 1 0 0 0 1 1 2 2 0 0 0 1 0 0 1 0 0 0 2 1 2 0 0 1 1 1 1 2 1 1 0 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 1 1 1 1 1 2 0 2 1 0 2 1 1 0 1 0 1 1 1 1 1 1\n 1 0 1 2 2 0 2 2 1 1 0 1 2 2 1 2 0 1 0 0 1 2 1 0 2 1 1 1 1 1 1 0 1 1 0 1 2\n 1 0 1 2 2 1 2 1 1 0 0 0 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 2 2 1 0 0 1 0 1 1 1\n 1 0 0 1 1 2 2 1 2 2 1 1 2 1 1 0 1 0 2 2 1 2 2 2 1 2 1 0 1 2 0 2 0 2 0 1 2\n 0 1 0 1 2 2 0 0 0 2 1 2 1 2 2 1 1 1 1 0 0 2 0 2 1 1 1 2 1 2 0 1]\nTree 4\n[2 0 1 2 1 2 1 0 1 0 1 0 1 1 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 1 1 1 2 1 1 0\n 1 1 0 0 1 0 1 1 2 2 1 0 0 1 1 2 1 0 0 0 1 0 2 1 0 1 1 0 2 1 1 0 0 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 1 1 1 1 1 2 0 2 1 0 2 1 1 1 1 0 2 1 1 1 1 1\n 1 0 1 2 2 2 1 2 0 1 0 1 2 2 1 2 1 1 0 0 1 1 1 0 2 0 1 1 1 1 1 0 1 1 0 0 2\n 1 0 1 1 2 1 2 1 1 2 0 0 1 2 1 1 2 2 1 1 2 1 1 1 1 1 1 2 1 1 0 0 1 0 1 1 0\n 1 0 0 1 1 2 2 1 2 2 1 1 2 1 1 1 1 0 1 1 1 1 2 2 1 2 1 2 1 2 0 1 0 2 0 1 2\n 0 1 0 1 2 1 0 1 0 2 1 2 1 2 1 1 1 1 1 0 0 2 0 2 1 1 1 0 1 1 0 1]\nTree 5\n[2 0 1 2 1 2 1 0 1 0 1 0 1 1 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 0 2 1 2 1 1 0\n 1 1 0 0 1 0 1 1 2 2 1 0 0 1 0 0 1 0 0 0 2 0 2 1 0 1 1 0 2 1 1 0 1 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 2 1 1 1 1 2 0 2 1 0 2 1 1 0 1 0 2 1 1 1 1 1\n 1 0 1 2 2 2 2 2 0 1 0 1 2 2 1 2 0 2 0 0 1 1 1 0 2 0 1 1 1 1 1 0 1 1 0 0 1\n 1 0 1 0 2 1 2 1 1 2 0 0 2 2 1 0 2 2 1 1 2 1 2 1 1 1 1 2 1 1 0 2 1 0 1 1 0\n 1 0 0 1 1 0 2 1 2 2 1 1 2 1 1 1 1 0 1 0 1 2 2 2 1 2 1 2 1 2 0 2 0 0 0 1 2\n 1 2 0 1 2 2 0 1 0 2 1 2 1 2 2 1 1 1 1 0 0 2 0 1 1 1 1 0 1 0 0 1]\nTree 6\n[2 0 1 2 1 1 1 0 1 1 1 0 1 0 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 0 2 1 2 1 1 0\n 1 1 0 0 0 1 1 1 2 2 0 0 1 1 1 0 1 0 0 0 1 1 2 1 0 1 1 0 1 1 1 0 0 2 0 2 1\n 0 1 2 1 1 2 1 1 2 1 1 1 0 1 0 2 0 1 1 1 2 1 2 1 0 2 1 1 0 1 0 2 1 1 1 1 1\n 1 0 1 2 2 2 2 2 1 1 1 1 2 1 1 2 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 2\n 1 0 1 2 2 1 1 1 1 2 0 0 1 1 1 0 2 2 1 0 2 1 2 1 1 1 1 2 1 1 0 2 2 0 1 1 1\n 1 0 0 1 1 0 2 1 2 1 1 1 2 1 1 0 1 0 2 1 1 2 0 2 1 2 1 2 1 2 0 1 0 1 0 1 2\n 0 2 0 1 2 2 0 1 0 1 1 2 1 2 2 1 1 1 1 0 0 2 1 1 1 1 1 0 1 1 0 1]\nTree 7\n[1 0 1 2 1 1 1 1 2 0 1 0 1 1 0 1 2 0 1 1 2 1 0 1 0 1 2 0 2 0 0 2 1 2 1 1 0\n 1 1 0 0 0 1 1 1 2 2 1 0 0 0 1 2 1 0 1 0 2 0 2 1 0 1 1 0 1 1 1 0 1 2 0 2 1\n 1 2 1 1 1 2 1 1 2 1 1 0 0 2 0 2 1 1 1 1 2 0 2 1 0 2 1 1 0 1 0 2 1 1 1 1 1\n 1 0 1 2 2 0 1 1 0 1 0 1 2 2 1 2 1 2 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 2\n 1 0 1 2 2 1 2 1 1 2 0 0 1 1 1 0 2 2 1 1 2 1 0 1 1 1 2 2 1 1 0 0 1 0 1 1 1\n 1 0 0 1 1 0 2 1 2 2 1 1 1 1 1 0 1 1 1 1 1 2 2 2 1 2 1 2 1 2 0 1 0 1 0 1 2\n 1 1 1 1 2 2 0 1 0 2 1 2 1 2 2 1 1 1 1 0 0 0 1 1 1 1 1 2 1 2 0 1]\nTree 8\n[1 0 1 2 1 2 1 0 1 0 1 0 1 1 0 1 2 2 1 1 2 1 0 1 2 1 2 0 2 0 0 2 1 2 1 1 0\n 1 1 0 0 1 1 1 1 2 2 0 0 0 1 0 1 1 0 0 0 2 1 2 1 0 1 1 0 1 1 1 1 1 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 2 1 1 1 1 2 0 2 1 0 2 1 1 0 1 0 2 1 1 1 1 1\n 1 0 1 2 2 2 2 2 0 1 0 1 2 2 1 2 1 2 0 0 1 2 1 1 2 0 1 1 1 1 1 1 1 1 0 1 1\n 1 0 1 2 2 1 1 1 1 2 0 0 1 2 1 0 2 2 1 1 2 1 2 1 1 1 1 2 1 1 0 2 1 0 1 1 0\n 1 0 0 1 1 0 2 1 2 2 1 1 2 1 0 0 1 0 1 2 1 2 0 2 1 2 1 2 1 2 0 2 0 1 0 1 2\n 1 2 0 1 2 2 0 1 0 2 1 2 1 2 2 1 1 1 1 0 0 2 0 1 1 1 1 0 1 2 0 1]\nTree 9\n[2 0 1 1 1 2 2 0 1 1 1 1 1 0 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 1 1 1 2 1 1 0\n 1 1 0 0 0 2 1 1 2 2 0 0 1 1 2 1 1 0 0 0 2 0 2 1 0 1 1 1 1 1 1 1 1 2 0 2 1\n 1 1 2 1 1 2 1 1 2 1 1 1 0 2 0 2 1 1 1 1 2 1 2 1 0 2 1 1 0 1 0 2 1 1 2 1 1\n 1 0 1 2 2 2 2 2 1 1 1 1 2 2 1 2 1 1 0 0 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 1 1\n 1 0 1 2 2 0 1 1 1 2 0 0 2 2 1 0 2 2 1 1 2 1 1 1 1 1 1 2 1 1 0 2 1 1 1 1 1\n 1 0 0 1 1 0 2 1 2 2 1 1 2 1 0 0 1 0 2 1 1 2 0 2 1 2 1 2 1 2 0 1 0 0 0 1 2\n 0 2 0 1 2 2 0 0 0 2 1 2 1 2 2 1 1 1 1 0 0 2 2 1 1 1 0 0 1 2 0 1]\nTree 10\n[2 0 1 2 1 2 2 0 1 0 1 0 1 1 0 1 2 0 1 1 2 1 0 1 2 1 2 0 2 0 0 2 1 2 1 1 0\n 1 2 0 0 2 0 1 1 2 2 0 0 0 1 0 0 1 0 0 0 1 1 2 1 0 2 1 0 1 1 1 1 0 2 0 2 1\n 1 1 2 1 1 1 1 1 2 0 0 1 1 1 0 1 1 1 1 1 2 1 2 1 0 1 1 1 1 1 0 2 1 1 0 1 1\n 1 0 1 2 2 2 2 1 1 1 0 1 2 2 1 2 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1\n 1 0 1 1 2 1 2 1 1 0 0 0 1 1 1 1 2 2 1 1 2 1 2 1 1 1 1 2 1 1 0 2 2 0 1 1 1\n 1 0 0 1 1 0 2 1 2 1 1 1 1 1 1 1 1 0 1 1 1 2 0 2 1 2 1 2 1 2 0 1 0 0 0 1 2\n 0 2 0 1 2 2 0 1 0 2 1 2 1 2 1 1 1 1 1 0 0 2 1 1 1 1 1 0 1 2 0 1]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2qQ84BJRcNP",
        "tags": []
      },
      "source": [
        "# Evaluate the results using accuracy, precision, recall and f-measure\n",
        "for j in range(n):\n",
        "    print(\"Tree\",(j+1))\n",
        "    print(\"Accuracy\",accuracy_score(y_test,pred[j]))\n",
        "    print(\"Precision\",precision_score(y_test,pred[j],labels=[0,1,2],average=\"macro\"))\n",
        "    print(\"Recall\",recall_score(y_test,pred[j],labels=[0,1,2],average=\"macro\"))\n",
        "    print(\"F1 score\",f1_score(y_test,pred[j],labels=[0,1,2],average=\"macro\"))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tree 1\nAccuracy 0.905511811023622\nPrecision 0.8956940836940838\nRecall 0.9099961919525058\nF1 score 0.902301747311828\nTree 2\nAccuracy 0.8385826771653543\nPrecision 0.836283741368487\nRecall 0.8268293765970588\nF1 score 0.8313427010148322\nTree 3\nAccuracy 0.8188976377952756\nPrecision 0.8027974879699862\nRecall 0.8195940863579053\nF1 score 0.8101241467222723\nTree 4\nAccuracy 0.8464566929133859\nPrecision 0.8412238612439332\nRecall 0.834397702791985\nF1 score 0.8376821598404663\nTree 5\nAccuracy 0.8937007874015748\nPrecision 0.8803037135618884\nRecall 0.9083787809672978\nF1 score 0.8920258004026284\nTree 6\nAccuracy 0.8661417322834646\nPrecision 0.8691399945502946\nRecall 0.8587120187630438\nF1 score 0.8635352733939824\nTree 7\nAccuracy 0.8740157480314961\nPrecision 0.8642449874030804\nRecall 0.855129359238821\nF1 score 0.8594285810173448\nTree 8\nAccuracy 0.9094488188976378\nPrecision 0.9038240555751426\nRecall 0.9128932683677741\nF1 score 0.9075393421442791\nTree 9\nAccuracy 0.8346456692913385\nPrecision 0.8324156026166275\nRecall 0.8357002434190077\nF1 score 0.8334447942894615\nTree 10\nAccuracy 0.8543307086614174\nPrecision 0.8567019400352733\nRecall 0.8454148013289143\nF1 score 0.8504541696120644\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_-xfr-CRoDa",
        "tags": []
      },
      "source": [
        "# Compare different voting mechanisms and their accuracies\n",
        "print(\"Max Voting\")\n",
        "pred=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_test[j]))\n",
        "fp=mode(pred)\n",
        "print(\"Final Prediction\",fp)\n",
        "print(\"Accuracy\",accuracy_score(y_test,fp))\n",
        "print(\"Average Voting\")\n",
        "pred=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_test[j]))\n",
        "fp=average(pred)\n",
        "print(\"Final Prediction\",fp)\n",
        "for i in range(len(fp)):\n",
        "    if(fp[i]<=0.5):\n",
        "        fp[i]=0\n",
        "    elif(fp[i]>=1.5):\n",
        "        fp[i]=2\n",
        "    else:\n",
        "        fp[i]=1\n",
        "print(\"Accuracy\",accuracy_score(y_test,fp))\n",
        "print(\"Weighted Average Voting\")\n",
        "pred=[]\n",
        "acc=[]\n",
        "for j in range(n):\n",
        "    pred.append(trees[j].predict(random_x_test[j]))\n",
        "    acc.append(accuracy_score(y_test,pred[j]))\n",
        "acc=np.array(acc)\n",
        "for i in range(len(pred)):\n",
        "    pred[i]=(pred[i]*acc[i])\n",
        "fp=average(pred)\n",
        "print(\"Final Prediction\",fp)\n",
        "for i in range(len(fp)):\n",
        "    if(fp[i]<=0.5):\n",
        "        fp[i]=0\n",
        "    elif(fp[i]>=1.5):\n",
        "        fp[i]=2\n",
        "    else:\n",
        "        fp[i]=1\n",
        "print(\"Accuracy\",accuracy_score(y_test,fp))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Max Voting\nFinal Prediction [2, 0, 1, 2, 1, 2, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 0, 1, 1, 2, 1, 0, 1, 2, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 2, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 2, 0, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 0, 2, 0, 2, 1, 1, 1, 1, 2, 0, 2, 1, 0, 2, 1, 1, 0, 1, 0, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 2, 0, 1, 0, 1, 2, 2, 1, 2, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 0, 0, 1, 1, 1, 0, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 2, 0, 1, 0, 0, 0, 1, 2, 0, 2, 0, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 0, 0, 2, 1, 1, 1, 1, 1, 0, 1, 2, 0, 1]\nAccuracy 0.9251968503937008\nAverage Voting\nFinal Prediction [1.5, 0.0, 1.0, 1.9, 1.0, 1.7, 1.1, 0.1, 1.1, 0.2, 1.0, 0.2, 1.0, 0.7, 0.0, 1.0, 2.0, 0.4, 1.0, 1.0, 1.8, 1.0, 0.0, 1.0, 1.8, 1.0, 2.0, 0.0, 2.0, 0.0, 0.4, 1.7, 1.0, 2.0, 1.0, 1.0, 0.1, 1.0, 1.2, 0.1, 0.0, 0.5, 0.7, 1.0, 1.0, 2.0, 2.0, 0.3, 0.0, 0.2, 0.9, 0.5, 0.7, 1.0, 0.0, 0.1, 0.1, 1.6, 0.5, 2.0, 0.9, 0.0, 1.1, 1.0, 0.2, 1.3, 1.2, 1.0, 0.6, 0.5, 2.0, 0.1, 2.0, 1.0, 0.9, 1.1, 1.9, 1.0, 1.0, 1.9, 1.0, 1.0, 2.0, 0.9, 0.9, 0.9, 0.1, 1.6, 0.0, 1.6, 0.9, 1.0, 1.0, 1.0, 2.0, 0.4, 2.0, 0.9, 0.0, 1.9, 1.0, 1.0, 0.2, 1.0, 0.0, 1.9, 1.0, 1.0, 0.9, 1.0, 1.1, 1.0, 0.0, 1.0, 2.0, 2.0, 1.6, 1.7, 1.8, 0.5, 1.0, 0.3, 1.0, 2.0, 1.9, 1.0, 2.0, 0.7, 1.5, 0.0, 0.0, 1.0, 1.3, 1.0, 0.2, 1.4, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.8, 1.5, 1.0, 0.0, 1.0, 1.5, 2.0, 0.9, 1.7, 1.0, 1.0, 1.4, 0.0, 0.0, 1.2, 1.5, 1.0, 0.4, 2.0, 1.9, 1.0, 0.9, 2.0, 1.0, 1.4, 1.0, 1.0, 1.0, 1.1, 2.0, 1.1, 1.0, 0.0, 1.2, 1.2, 0.1, 1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 2.0, 1.0, 2.0, 1.8, 1.0, 1.0, 1.8, 1.0, 1.0, 0.3, 1.0, 0.1, 1.3, 1.1, 1.0, 1.9, 0.8, 2.0, 1.0, 2.0, 1.0, 1.8, 1.0, 2.0, 0.0, 1.4, 0.0, 0.8, 0.0, 1.0, 2.0, 0.4, 1.7, 0.1, 1.0, 2.0, 1.9, 0.0, 0.8, 0.0, 1.9, 1.0, 2.0, 1.0, 2.0, 1.7, 1.0, 1.0, 0.9, 1.0, 0.0, 0.1, 1.6, 0.7, 1.2, 1.0, 1.0, 0.9, 0.4, 1.0, 1.5, 0.0, 1.0]\nAccuracy 0.9094488188976378\nWeighted Average Voting\nFinal Prediction [1.291732283464567, 0.0, 0.8641732283464568, 1.6448818897637796, 0.8641732283464568, 1.4637795275590553, 0.9492125984251969, 0.08740157480314961, 0.9515748031496063, 0.1700787401574803, 0.8641732283464568, 0.16732283464566927, 0.8708661417322835, 0.6035433070866143, 0.0, 0.8641732283464568, 1.7283464566929136, 0.36299212598425196, 0.8641732283464568, 0.8641732283464568, 1.5645669291338584, 0.8641732283464568, 0.0, 0.8641732283464568, 1.5535433070866145, 0.8641732283464568, 1.7283464566929136, 0.0, 1.7283464566929136, 0.0, 0.33385826771653543, 1.4783464566929136, 0.8641732283464568, 1.7283464566929136, 0.8641732283464568, 0.8641732283464568, 0.08385826771653543, 0.8641732283464568, 1.0314960629921262, 0.08188976377952756, 0.0, 0.43582677165354333, 0.6062992125984252, 0.8641732283464568, 0.8641732283464568, 1.7283464566929136, 1.7283464566929136, 0.26141732283464564, 0.0, 0.1700787401574803, 0.7767716535433072, 0.42559055118110234, 0.6023622047244095, 0.8641732283464568, 0.0, 0.08740157480314961, 0.08385826771653543, 1.3811023622047245, 0.428740157480315, 1.7283464566929136, 0.7822834645669292, 0.0, 0.9496062992125985, 0.8641732283464568, 0.1653543307086614, 1.1287401574803149, 1.0299212598425196, 0.8641732283464568, 0.5161417322834646, 0.44173228346456694, 1.7283464566929136, 0.08385826771653543, 1.7283464566929136, 0.8641732283464568, 0.7775590551181104, 0.9515748031496063, 1.640944881889764, 0.8641732283464568, 0.8641732283464568, 1.642913385826772, 0.8641732283464568, 0.8641732283464568, 1.7283464566929136, 0.7787401574803151, 0.7787401574803151, 0.7767716535433072, 0.08543307086614174, 1.3885826771653544, 0.0, 1.3925196850393702, 0.7775590551181104, 0.8641732283464568, 0.8641732283464568, 0.8641732283464568, 1.7283464566929136, 0.3393700787401575, 1.7283464566929136, 0.7736220472440947, 0.0, 1.642913385826772, 0.8641732283464568, 0.8641732283464568, 0.1700787401574803, 0.8641732283464568, 0.0, 1.646456692913386, 0.8641732283464568, 0.8641732283464568, 0.7783464566929135, 0.8641732283464568, 0.9480314960629921, 0.8641732283464568, 0.0, 0.8641732283464568, 1.7283464566929136, 1.7283464566929136, 1.3897637795275593, 1.4657480314960631, 1.5555118110236221, 0.421259842519685, 0.8641732283464568, 0.25393700787401574, 0.8641732283464568, 1.7283464566929136, 1.6417322834645671, 0.8641732283464568, 1.7283464566929136, 0.60748031496063, 1.3062992125984254, 0.0, 0.0, 0.8641732283464568, 1.1275590551181103, 0.8641732283464568, 0.18149606299212598, 1.2110236220472443, 0.3413385826771654, 0.8641732283464568, 0.8641732283464568, 0.8641732283464568, 0.8641732283464568, 0.8641732283464568, 0.09094488188976378, 0.8641732283464568, 0.8641732283464568, 0.0, 0.6901574803149607, 1.2885826771653544, 0.8641732283464568, 0.0, 0.8641732283464568, 1.2889763779527559, 1.7283464566929136, 0.780708661417323, 1.4673228346456695, 0.8641732283464568, 0.8641732283464568, 1.225984251968504, 0.0, 0.0, 1.037007874015748, 1.2944881889763782, 0.8641732283464568, 0.33582677165354335, 1.7283464566929136, 1.644488188976378, 0.8641732283464568, 0.7775590551181104, 1.7283464566929136, 0.8641732283464568, 1.2196850393700789, 0.8641732283464568, 0.8641732283464568, 0.8641732283464568, 0.9515748031496063, 1.7283464566929136, 0.9460629921259842, 0.8641732283464568, 0.0, 1.0527559055118112, 1.036220472440945, 0.08346456692913386, 0.8641732283464568, 0.8641732283464568, 0.5086614173228348, 0.8641732283464568, 0.0, 0.0, 0.8641732283464568, 0.8641732283464568, 0.5007874015748032, 1.7283464566929136, 0.8641732283464568, 1.7283464566929136, 1.5562992125984254, 0.8641732283464568, 0.8641732283464568, 1.5555118110236221, 0.8641732283464568, 0.8641732283464568, 0.25944881889763777, 0.8641732283464568, 0.08740157480314961, 1.1161417322834646, 0.9476377952755906, 0.8641732283464568, 1.6437007874015748, 0.6866141732283465, 1.7283464566929136, 0.8641732283464568, 1.7283464566929136, 0.8641732283464568, 1.5645669291338584, 0.8641732283464568, 1.7283464566929136, 0.0, 1.2169291338582677, 0.0, 0.6885826771653544, 0.0, 0.8641732283464568, 1.7283464566929136, 0.35826771653543305, 1.474409448818898, 0.08740157480314961, 0.8641732283464568, 1.7283464566929136, 1.6437007874015748, 0.0, 0.6988188976377954, 0.0, 1.6417322834645671, 0.8641732283464568, 1.7283464566929136, 0.8641732283464568, 1.7283464566929136, 1.4744094488188977, 0.8641732283464568, 0.8641732283464568, 0.7736220472440947, 0.8641732283464568, 0.0, 0.08385826771653543, 1.37244094488189, 0.6007874015748031, 1.0307086614173229, 0.8641732283464568, 0.8641732283464568, 0.780708661417323, 0.33858267716535434, 0.8641732283464568, 1.2944881889763782, 0.0, 0.8641732283464568]\nAccuracy 0.8818897637795275\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2UXYktmRryu"
      },
      "source": [
        "# Compare the Random forest models with different number of trees N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_grD0B0qRwOI",
        "tags": []
      },
      "source": [
        "# Compare different values for minimum number of features needed for individual trees\n",
        "for i in range(n):\n",
        "    print(\"Tree\",(i+1))\n",
        "    print(random_x_train[i].columns)\n",
        "    print(len(random_x_train[i].columns))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Tree 1\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;skewness_about&#39;, &#39;scaled_radius_of_gyration.1&#39;, &#39;skewness_about.2&#39;,\n       &#39;scaled_variance.1&#39;, &#39;scaled_radius_of_gyration&#39;,\n       &#39;pr.axis_aspect_ratio&#39;, &#39;scaled_variance&#39;, &#39;max.length_aspect_ratio&#39;,\n       &#39;hollows_ratio&#39;, &#39;skewness_about.1&#39;, &#39;scatter_ratio&#39;,\n       &#39;max.length_rectangularity&#39;],\n      dtype=&#39;object&#39;)\n16\nTree 2\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;scatter_ratio&#39;, &#39;scaled_variance&#39;],\n      dtype=&#39;object&#39;)\n6\nTree 3\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;hollows_ratio&#39;, &#39;skewness_about.1&#39;, &#39;scaled_variance&#39;,\n       &#39;pr.axis_aspect_ratio&#39;, &#39;scaled_radius_of_gyration&#39;,\n       &#39;pr.axis_rectangularity&#39;, &#39;scaled_radius_of_gyration.1&#39;],\n      dtype=&#39;object&#39;)\n11\nTree 4\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;scatter_ratio&#39;, &#39;elongatedness&#39;, &#39;scaled_radius_of_gyration&#39;,\n       &#39;max.length_aspect_ratio&#39;, &#39;scaled_variance&#39;],\n      dtype=&#39;object&#39;)\n9\nTree 5\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;skewness_about&#39;, &#39;max.length_aspect_ratio&#39;, &#39;pr.axis_rectangularity&#39;,\n       &#39;scatter_ratio&#39;, &#39;skewness_about.1&#39;, &#39;scaled_radius_of_gyration&#39;,\n       &#39;scaled_radius_of_gyration.1&#39;, &#39;elongatedness&#39;,\n       &#39;max.length_rectangularity&#39;, &#39;skewness_about.2&#39;, &#39;hollows_ratio&#39;],\n      dtype=&#39;object&#39;)\n15\nTree 6\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;pr.axis_aspect_ratio&#39;, &#39;scatter_ratio&#39;, &#39;skewness_about.1&#39;],\n      dtype=&#39;object&#39;)\n7\nTree 7\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;pr.axis_aspect_ratio&#39;, &#39;skewness_about.2&#39;, &#39;max.length_aspect_ratio&#39;,\n       &#39;skewness_about&#39;, &#39;pr.axis_rectangularity&#39;,\n       &#39;max.length_rectangularity&#39;],\n      dtype=&#39;object&#39;)\n10\nTree 8\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;skewness_about.2&#39;, &#39;scatter_ratio&#39;, &#39;skewness_about&#39;,\n       &#39;scaled_radius_of_gyration&#39;, &#39;scaled_variance&#39;, &#39;hollows_ratio&#39;,\n       &#39;pr.axis_aspect_ratio&#39;, &#39;max.length_rectangularity&#39;,\n       &#39;scaled_radius_of_gyration.1&#39;, &#39;skewness_about.1&#39;,\n       &#39;max.length_aspect_ratio&#39;],\n      dtype=&#39;object&#39;)\n15\nTree 9\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;skewness_about.1&#39;, &#39;scatter_ratio&#39;, &#39;max.length_rectangularity&#39;],\n      dtype=&#39;object&#39;)\n7\nTree 10\nIndex([&#39;compactness&#39;, &#39;circularity&#39;, &#39;distance_circularity&#39;, &#39;radius_ratio&#39;,\n       &#39;scaled_variance.1&#39;, &#39;hollows_ratio&#39;, &#39;scatter_ratio&#39;],\n      dtype=&#39;object&#39;)\n7\n"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGVYWKUcRnhA"
      },
      "source": [
        "## Part 2: Random Forest using Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vJ02XgwRm-O"
      },
      "source": [
        "# Use the preprocessed dataset here\n",
        "x=data.iloc[:,:-1]\n",
        "y=data.iloc[:,-1:]\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHEEc7BrSDG0"
      },
      "source": [
        "# Train the Random Forest Model using builtin Sklearn Dataset\n",
        "rf=RandomForestClassifier()\n",
        "rf.fit(x_train,y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "RandomForestClassifier()"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-YJEeqPSIk1",
        "tags": []
      },
      "source": [
        "# Test the model with testing set and print the accuracy, precision, recall and f-measure\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.9803149606299213\nPrecision 0.9759305210918114\nRecall 0.9814835196191128\nF1 score 0.9784701701259646\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlwe8gonSVFd",
        "tags": []
      },
      "source": [
        "# Play with parameters such as\n",
        "# number of decision trees\n",
        "# Criterion for splitting\n",
        "# Max depth\n",
        "# Minimum samples per split and leaf\n",
        "rf=RandomForestClassifier(n_estimators=10)\n",
        "rf.fit(x_train,y_train)\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.952755905511811\nPrecision 0.9471653627692637\nRecall 0.9551507814219679\nF1 score 0.9507602118794883\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.968503937007874\nPrecision 0.9678437898023748\nRecall 0.965251791522978\nF1 score 0.9664366781405197\n"
        }
      ],
      "source": [
        "rf=RandomForestClassifier(criterion=\"entropy\")\n",
        "rf.fit(x_train,y_train)\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.8622047244094488\nPrecision 0.850806692003875\nRecall 0.8777097039808904\nF1 score 0.8610907610907611\n"
        }
      ],
      "source": [
        "rf=RandomForestClassifier(max_depth=3)\n",
        "rf.fit(x_train,y_train)\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.9724409448818898\nPrecision 0.9708610358696544\nRecall 0.9736672618028551\nF1 score 0.9719775613701999\n"
        }
      ],
      "source": [
        "rf=RandomForestClassifier(min_samples_leaf=3)\n",
        "rf.fit(x_train,y_train)\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Accuracy 0.9763779527559056\nPrecision 0.9733664185277089\nRecall 0.9789582670938604\nF1 score 0.9759256408638781\n"
        }
      ],
      "source": [
        "rf=RandomForestClassifier(min_samples_split=4)\n",
        "rf.fit(x_train,y_train)\n",
        "pred=rf.predict(x_test)\n",
        "print(\"Accuracy\",accuracy_score(y_test,pred))\n",
        "print(\"Precision\",precision_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"Recall\",recall_score(y_test,pred,labels=[0,1,2],average=\"macro\"))\n",
        "print(\"F1 score\",f1_score(y_test,pred,labels=[0,1,2],average=\"macro\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}